{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e15f70f8-6456-4903-9d13-88958c5d2fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c626096-bb96-4944-afdc-e1353ea24734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is introduction to nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is likely to be useful, to people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning is the new electricity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there would be less hype around ai and more ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python is the best tool!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>r is a good language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i like this book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i want more books like this</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets\n",
       "0                        this is introduction to nlp\n",
       "1               it is likely to be useful, to people\n",
       "2            machine learning is the new electricity\n",
       "3  there would be less hype around ai and more ac...\n",
       "4                           python is the best tool!\n",
       "5                               r is a good language\n",
       "6                                   i like this book\n",
       "7                        i want more books like this"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "tweets = [\n",
    "    \"This is introduction to NLP\",\n",
    "    \"It is likely to be useful, to people\",\n",
    "    \"Machine learning is the new electricity\",\n",
    "    \"There would be less hype around AI and more action going forward\",\n",
    "    \"Python is the best tool!\",\n",
    "    \"R is a good language\",\n",
    "    \"I like this book\",\n",
    "    \"I want more books like this\"\n",
    "    ]\n",
    "\n",
    "#f_tweets = []\n",
    "#for t in tweets:\n",
    "#    f_tweets.append(t.lower())\n",
    "#f_tweets\n",
    "\n",
    "# alternative:\n",
    "f_tweets = [t.lower() for t in tweets]\n",
    "\n",
    "tweets_df = pd.DataFrame(f_tweets, columns=['tweets'])\n",
    "tweets_df\n",
    "\n",
    "# or lower the Dataframe itself:\n",
    "#df['tweets'] = df['tweets'].str.lower()\n",
    "#df['tweets'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6966bde-8a2e-469d-a8c9-b980bf8cd12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is introduction to nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is likely to be useful to people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning is the new electricity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there would be less hype around ai and more ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python is the best tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>r is a good language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i like this book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i want more books like this</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets\n",
       "0                        this is introduction to nlp\n",
       "1                it is likely to be useful to people\n",
       "2            machine learning is the new electricity\n",
       "3  there would be less hype around ai and more ac...\n",
       "4                            python is the best tool\n",
       "5                               r is a good language\n",
       "6                                   i like this book\n",
       "7                        i want more books like this"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- with REPLACE --------\n",
    "#f_tweets = [t.lower().replace(',', '').replace('!', '') for t in tweets]\n",
    "\n",
    "\n",
    "# --- with REGEX ----------\n",
    "# ^ invert\n",
    "# \\w all characters from a-Z, all numbers, underscore _ (no whitespace!!! -> \\s needed)\n",
    "# \\s whitespace\n",
    "\n",
    "f_tweets = [re.sub(r'[^\\w\\s]', '', t.lower()) for t in tweets]\n",
    "f_tweets\n",
    "\n",
    "tweets_df = pd.DataFrame(f_tweets, columns=['tweets'])\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff509f-d0e3-4302-82b0-adebbce2a6cf",
   "metadata": {},
   "source": [
    "## Tokenisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cea73cd-64b8-46a6-a199-d0379e8dcf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'first',\n",
       " 'sentence.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'second',\n",
       " 'one.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ACHTUNG! Split berücksichtigt keine Satzzeichen\n",
    "\n",
    "text = \"This is the first sentence. This is the second one.\"  \n",
    "list_of_words = text.split()  \n",
    "list_of_words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d3d32d-5e83-4730-bf25-986f55d7aa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'there', '!', 'Welcome', 'to', 'the', 'programming', 'world', '.']\n"
     ]
    }
   ],
   "source": [
    "# NLTK berücksichtigt Satzzeichen\n",
    "\n",
    "from nltk.tokenize import word_tokenize \n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "text=\"Hello there! Welcome to the programming world.\"\n",
    "print(word_tokenize(text)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d61c6f-1bc6-4da0-96cd-921d0b829eb3",
   "metadata": {},
   "source": [
    "## Tokenisieren mit Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb512fec-b58a-4873-9ac6-50ba7c6bb6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple erwägt den Kauf eines österreichischen Startups um 6 Mio. Euro.\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Apple erwägt den Kauf eines österreichischen Startups um 6 Mio. Euro.\") \n",
    "print(doc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ed75bc9-a4e8-43e0-9f8b-a79efb2ab898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple erwägt den Kauf eines österreichischen Startups um 6 Mio. Euro."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "text = \"Apple erwägt den Kauf eines österreichischen Startups um 6 Mio. Euro.\"\n",
    "\n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1b9fe21-683a-41f0-b8ec-4970b8a39b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple                <class 'spacy.tokens.token.Token'>\n",
      "erwägt               <class 'spacy.tokens.token.Token'>\n",
      "den                  <class 'spacy.tokens.token.Token'>\n",
      "Kauf                 <class 'spacy.tokens.token.Token'>\n",
      "eines                <class 'spacy.tokens.token.Token'>\n",
      "österreichischen     <class 'spacy.tokens.token.Token'>\n",
      "Startups             <class 'spacy.tokens.token.Token'>\n",
      "um                   <class 'spacy.tokens.token.Token'>\n",
      "6                    <class 'spacy.tokens.token.Token'>\n",
      "Mio.                 <class 'spacy.tokens.token.Token'>\n",
      "Euro                 <class 'spacy.tokens.token.Token'>\n",
      ".                    <class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "\tprint(f\"{token.text:{20}}\",type(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc4bef1-82cc-46f5-b668-b076281d02f3",
   "metadata": {},
   "source": [
    "## POS mit Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45381339-eee9-4b47-9029-20e0e3a300d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN\n",
      "erwägt VERB\n",
      "den DET\n",
      "Kauf NOUN\n",
      "eines DET\n",
      "österreichischen ADJ\n",
      "Startups NOUN\n",
      "um ADP\n",
      "6 NUM\n",
      "Mio. NOUN\n",
      "Euro NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"de_core_news_sm\" )\n",
    "words = nlp(\"Apple erwägt den Kauf eines österreichischen Startups um 6 Mio. Euro.\")\n",
    "\n",
    "for token in words:\n",
    "\tprint(token.text, token.pos_) #.pos_ = Type (Verb, NOUN, NUM, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "341994bb-f742-494b-854c-182f3b881413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NOUN': 4, 'DET': 2, 'PROPN': 1, 'VERB': 1, 'ADJ': 1, 'ADP': 1, 'NUM': 1, 'PUNCT': 1})\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "text = \"Apple erwägt den Kauf eines österreichischen Startups um 6 Mio. Euro.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Häufigkeit der Wortklassen zählen\n",
    "pos_counts = Counter([token.pos_ for token in doc])\n",
    "\n",
    "print(pos_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e319b31-2569-4211-b933-9b8e02abf447",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "06806488-d911-4ea0-a994-a7461425dfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG Companies, agencies, institutions, etc.\n",
      "U.K. 27 31 GPE Countries, cities, states\n",
      "1 45 46 MONEY Monetary values, including unit\n",
      "U.K. 81 85 GPE Countries, cities, states\n",
      "$1 billion 98 108 MONEY Monetary values, including unit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is looking at buying \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " startup for $\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " billionApple is looking at buying \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " startup for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $1 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "text = 'Apple is looking at buying U.K. startup for $1 billion''Apple is looking at buying U.K. startup for $1 billion'\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents: \n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_, \n",
    "          spacy.explain(ent.label_))\n",
    "    \n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b88e050a-5ecd-4423-962e-aaff44c8a81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function render in module spacy.displacy:\n",
      "\n",
      "render(docs: Union[Iterable[Union[spacy.tokens.doc.Doc, spacy.tokens.span.Span, dict]], spacy.tokens.doc.Doc, spacy.tokens.span.Span, dict], style: str = 'dep', page: bool = False, minify: bool = False, jupyter: Optional[bool] = None, options: Dict[str, Any] = {}, manual: bool = False) -> str\n",
      "    Render displaCy visualisation.\n",
      "    \n",
      "    docs (Union[Iterable[Union[Doc, Span, dict]], Doc, Span, dict]]): Document(s) to visualise.\n",
      "        a 'dict' is only allowed here when 'manual' is set to True\n",
      "    style (str): Visualisation style, 'dep' or 'ent'.\n",
      "    page (bool): Render markup as full HTML page.\n",
      "    minify (bool): Minify HTML markup.\n",
      "    jupyter (bool): Override Jupyter auto-detection.\n",
      "    options (dict): Visualiser-specific options, e.g. colors.\n",
      "    manual (bool): Don't parse `Doc` and instead expect a dict/list of dicts.\n",
      "    RETURNS (str): Rendered SVG or HTML markup.\n",
      "    \n",
      "    DOCS: https://spacy.io/api/top-level#displacy.render\n",
      "    USAGE: https://spacy.io/usage/visualizers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(displacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ef9034a7-6eb9-4ccf-a47a-2d9f3599dfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple      B ORG\n",
      "is         O \n",
      "looking    O \n",
      "at         O \n",
      "buying     O \n",
      "U.K.       B GPE\n",
      "startup    O \n",
      "for        O \n",
      "$          O \n",
      "1          B MONEY\n",
      "billionApple O \n",
      "is         O \n",
      "looking    O \n",
      "at         O \n",
      "buying     O \n",
      "U.K.       B GPE\n",
      "startup    O \n",
      "for        O \n",
      "$          B MONEY\n",
      "1          I MONEY\n",
      "billion    I MONEY\n"
     ]
    }
   ],
   "source": [
    "for token in doc:         \n",
    "    print(f'{token.text:10} {token.ent_iob_} {token.ent_type_}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fbc27415-0671-4018-a3ae-e4ca4a6eaead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[REDACTED] [REDACTED] der Republik Österreich beschloss am 25.März 2014, eine„ Unabhängige\\n\\n Untersuchungskommission zur transparenten Aufklärung der Vorkommnisse rund um die Hypo Group Alpe- Adria“ einzusetzen. Die Untersuchungskommission( [ REDACTED], [ REDACTED], [ REDACTED], [ REDACTED]) hat, beginnend mit 1.Mai 2014, durch[REDACTED][REDACTED][REDACTED][REDACTED] schafften Unterlagen und allgemein zugänglichen [REDACTED] sowie durch[REDACTED][REDACTED] [REDACTED] den maßgeblichen Sachverhalt festgestellt und nach fachlichen Kriterien bewertet.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Der Ministerrat der Republik Österreich beschloss am 25.März 2014, eine „Unabhängige\\nUntersuchungskommission zur transparenten Aufklärung der Vorkommnisse rund um die Hypo Group Alpe-Adria“ einzusetzen. Die Untersuchungskommission ([REDACTED], [REDACTED], [REDACTED], [REDACTED]) hat, beginnend mit 1.Mai 2014, durch Auswertung von beige-schafften Unterlagen und allgemein zugänglichen Quellen sowie durch Befragung von Auskunftspersonen den maßgeblichen Sachverhalt festgestellt und nach fachlichen Kriterien bewertet.\")\n",
    "\n",
    "new_text = []\n",
    "for token in doc:\n",
    "    if re.match(r\"PER\", token.ent_type_):\n",
    "        new_text.append(\"[REDACTED]\")\n",
    "    else:\n",
    "        new_text.append(token.text)\n",
    "\n",
    "redacted_text = \"\"\n",
    "for i in range(0, len(new_text)-1):\n",
    "    if (i > 0) & (new_text[i-1] == \"\\n\"):\n",
    "        redacted_text += \"\\n\"\n",
    "    if not ((new_text[i] == new_text[i+1]) & (new_text[i] == \"[REDACTED]\")):\n",
    "        if not (re.match(\"PUNCT|SPACE\", doc[i].pos_) or (i == 0)):\n",
    "            redacted_text += \" \"\n",
    "    redacted_text += new_text[i]\n",
    "if i == len(new_text)-2:\n",
    "    redacted_text += new_text[i+1]\n",
    "\n",
    "redacted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede3bc4-8fed-49ce-9e63-0bb2b32c0c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
